{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matthew\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Hidden4NetTuned(nn.Module):\n",
    "    def __init__(self, num_input, num_hid, num_out, batch_size=388):\n",
    "        super(Hidden4NetTuned, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.in_to_hid1 = nn.Linear(num_input, num_hid)\n",
    "        self.hid1_to_hid2 = nn.Linear(num_hid,num_hid)\n",
    "        self.hid2_to_hid3 = nn.Linear(num_hid,num_hid)\n",
    "        self.hid3_to_hid4 = nn.Linear(num_hid,num_hid)\n",
    "        self.hid4_to_out = nn.Linear(num_hid,num_out)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Take into account batch size here\n",
    "        hid1_sum = self.in_to_hid1(input)\n",
    "        self.hid1 = F.elu(hid1_sum, 1)\n",
    "\n",
    "        hid2_sum = self.hid1_to_hid2(self.hid1)\n",
    "        self.hid2 = F.elu(hid2_sum, 1)\n",
    "\n",
    "        hid3_sum = self.hid2_to_hid3(self.hid2)\n",
    "        self.hid3 = F.elu(hid3_sum, 1)\n",
    "\n",
    "        hid4_sum = self.hid3_to_hid4(self.hid3)\n",
    "        self.hid4 = F.elu(hid4_sum, 1)\n",
    "\n",
    "        preOutput = self.hid4_to_out(self.hid4)\n",
    "        output = F.elu(preOutput, 1)\n",
    "        return output\n",
    "\n",
    "def blackscholes(scaled_price, r, sigma, Tmt):\n",
    "    s = sigma * np.sqrt(Tmt)\n",
    "    d1 = (np.log(scaled_price) + (r + sigma**2/2)*(Tmt)) / s\n",
    "    d2 = d1 - s\n",
    "    optionValue = scaled_price * norm.cdf(d1) - np.exp(-r*Tmt) * norm.cdf(d2)\n",
    "    return optionValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_process():\n",
    "    def __init__(self, network, optimizer, dataset, epoch=10):\n",
    "        self.network = network\n",
    "        self.epoch = epoch\n",
    "        self.optimizer = optimizer\n",
    "        self.dataset = dataset\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.train_loader = None\n",
    "        self.test_loader = None\n",
    "        self.initalise_weights()\n",
    "        self.initialise_dataset()\n",
    "\n",
    "    def initalise_weights(self):\n",
    "        for m in list(self.network.parameters()):\n",
    "            # Initialize Weight Matrix\n",
    "            if m.dim() == 2:\n",
    "                torch.nn.init.xavier_uniform_(m, gain=nn.init.calculate_gain('relu'))\n",
    "            else:\n",
    "            # Initialize Bias\n",
    "                torch.nn.init.zeros_(m)\n",
    "\n",
    "    def initialise_dataset(self):\n",
    "        train_size = int(0.8 * len(self.dataset))\n",
    "        test_size = len(self.dataset) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(self.dataset, [train_size, test_size])\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.network.batch_size)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=self.network.batch_size)\n",
    "\n",
    "    def train_network(self):\n",
    "        self.network.train()\n",
    "        train_running_loss = 0.0\n",
    "        counter = 0\n",
    "        for batch_id, (data,target) in enumerate(self.train_loader):\n",
    "            counter += 1\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            self.optimizer.zero_grad()    # zero the gradients\n",
    "            output = self.network(data)       # apply network\n",
    "            loss = F.mse_loss(output, target)\n",
    "            train_running_loss += loss.item()\n",
    "            loss.backward()          # compute gradients\n",
    "            self.optimizer.step()         # update weights\n",
    "        \n",
    "        epoch_loss = train_running_loss / counter\n",
    "        return epoch_loss\n",
    "\n",
    "    # validation\n",
    "    def validate_network(self):\n",
    "        self.network.eval()\n",
    "        # we need two lists to keep track of class-wise accuracy\n",
    "        valid_running_loss = 0.0\n",
    "        counter = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (data, target) in enumerate(self.test_loader):\n",
    "                counter += 1\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                # forward pass\n",
    "                outputs = self.network(data)\n",
    "                # calculate the loss\n",
    "                loss = F.mse_loss(outputs, target).item()\n",
    "                valid_running_loss += loss\n",
    "            \n",
    "        epoch_loss = valid_running_loss / counter\n",
    "        return epoch_loss\n",
    "    \n",
    "    def start_train(self):\n",
    "        print('Start training loop')\n",
    "        for i in range(self.epoch):\n",
    "            print(f\"[INFO]: Epoch {i+1} of {self.epoch}\")\n",
    "            train_epoch_loss = self.train_network()\n",
    "            valid_epoch_loss = self.validate_network()\n",
    "            self.train_loss.append(train_epoch_loss)\n",
    "            self.valid_loss.append(valid_epoch_loss)\n",
    "            print(f\"Training loss: {train_epoch_loss:.3f}\")\n",
    "            print(f\"Validation loss: {valid_epoch_loss:.3f}\")\n",
    "        print('Training Complete')\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(\n",
    "            self.train_loss, color='orange', linestyle='-', \n",
    "            label='train loss'\n",
    "        )\n",
    "        plt.plot(\n",
    "            self.valid_loss, color='red', linestyle='-', \n",
    "            label='validation loss'\n",
    "        )\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training loop\n",
      "[INFO]: Epoch 1 of 200\n",
      "Training loss: 0.002\n",
      "Validation loss: 0.001\n",
      "[INFO]: Epoch 2 of 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Matthew\\Desktop\\COMP9417\\COMP9417-project\\ann_option.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=15'>16</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(net\u001b[39m.\u001b[39mparameters(),lr\u001b[39m=\u001b[39m\u001b[39m1.60E-04\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=16'>17</a>\u001b[0m full_network \u001b[39m=\u001b[39m network_process(net, optimizer, full_dataset, epoch\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=17'>18</a>\u001b[0m full_network\u001b[39m.\u001b[39;49mstart_train()\n",
      "\u001b[1;32mc:\\Users\\Matthew\\Desktop\\COMP9417\\COMP9417-project\\ann_option.ipynb Cell 3\u001b[0m in \u001b[0;36mnetwork_process.start_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=69'>70</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=70'>71</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[INFO]: Epoch \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=71'>72</a>\u001b[0m     train_epoch_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_network()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=72'>73</a>\u001b[0m     valid_epoch_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_network()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=73'>74</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loss\u001b[39m.\u001b[39mappend(train_epoch_loss)\n",
      "\u001b[1;32mc:\\Users\\Matthew\\Desktop\\COMP9417\\COMP9417-project\\ann_option.ipynb Cell 3\u001b[0m in \u001b[0;36mnetwork_process.train_network\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=31'>32</a>\u001b[0m train_running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=32'>33</a>\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_id, (data,target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=34'>35</a>\u001b[0m     counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matthew/Desktop/COMP9417/COMP9417-project/ann_option.ipynb#ch0000002?line=35'>36</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\Matthew\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Matthew\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Matthew\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\Matthew\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Matthew\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Matthew\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    139\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    140\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m    142\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[0;32m    143\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    145\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_input = 4\n",
    "num_hid = 400\n",
    "num_out = 1\n",
    "n = 1000000\n",
    "scaled_price = torch.FloatTensor(n).uniform_(0.4, 1.6)\n",
    "tau = torch.FloatTensor(n).uniform_(0.2, 1.1)\n",
    "r = torch.FloatTensor(n).uniform_(0.02, 0.1)\n",
    "sigma = torch.FloatTensor(n).uniform_(0.01, 1.0)\n",
    "input = torch.stack((scaled_price, tau, sigma, r), -1)\n",
    "blackScholesTarget = blackscholes(scaled_price, r, sigma, tau).float()\n",
    "full_dataset = torch.utils.data.TensorDataset(input, blackScholesTarget.reshape(-1, 1))\n",
    "\n",
    "\n",
    "net = Hidden4NetTuned(num_input, num_hid, num_out).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=1.60E-04)\n",
    "full_network = network_process(net, optimizer, full_dataset, epoch=200)\n",
    "full_network.start_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2dce539944995773076a20df5a7eecb6e3f5341be50a6e5d83cd55eac68256fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
